#! /usr/bin/env python
import sys, os
from ioutils import make_dir, prepare_output_file
from cmdtool import CommandLineTool, Argument
from formats import read_ct, score_structure, make_pair_list
from genomic_data import GenomicData
import logging
logging.basicConfig(level=logging.DEBUG)

def parse_filename(filename, name_dict=None):
    s = os.path.splitext(os.path.basename(filename))[0]
    d = {}
    for pair in s.split(','):
        key, value = pair.split('=')
        if name_dict is not None:
            d[name_dict[key]] = value
        else:
            d[key] = value
    return d

def import_matplotlib():
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    plt.rcParams['font.family'] = 'Arial'
    plt.rcParams['font.size'] = 12
    plt.rcParams['legend.fontsize'] = 12
    from matplotlib.backends.backend_pdf import PdfPages
    globals().update(locals())

class MetricTable(CommandLineTool):
    arguments = [Argument('experiment_type', type=str, required=True),
        Argument('data_name', type=str, required=True),
        Argument('region', type=str, required=True),
        Argument('outfile', type=str, short_opt='-o', required=True, help='output file'),
        Argument('metrics', type=list, default='accuracy,roc_auc,sensitivity,ppv')]
    def __call__(self):
        import glob
        import h5py
        records = []
        if self.experiment_type == 'icSHAPE':
            name_dict = {'d': 'data_name', 'w': 'window_size', 'p': 'percentile', 'm': 'model_name', 'r': 'region'}
            header = ['data_name', 'region', 'percentile', 'window_size', 'model_name'] + self.metrics
            for filename in glob.glob('metrics/{}/{}/*.h5'.format(self.experiment_type, self.data_name)):
                d = parse_filename(filename, name_dict)
                if d['region'] != self.region:
                    continue
                f = h5py.File(filename, 'r')
                record = [self.data_name, self.region, d['percentile'], d['window_size'], d['model_name']]
                grp = f['metrics']
                for metric in self.metrics:
                    record.append(str(grp[metric][()]))
                records.append(record)

        self.logger.info('save file: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        with open(self.outfile, 'w') as f:
            f.write('\t'.join(header) + '\n')
            for record in records:
                f.write('\t'.join(record) + '\n')

class MetricTableCross(CommandLineTool):
    arguments = [Argument('experiment_type', type=str, required=True),
        Argument('data_name', type=str, required=True),
        Argument('region', type=str, required=True),
        Argument('outfile', type=str, short_opt='-o', required=True, help='output file'),
        Argument('metrics', type=list, default='accuracy,roc_auc,sensitivity,ppv')]
    def __call__(self):
        import glob
        import h5py
        records = []
        name_dict = {'d': 'data_name', 'w': 'window_size', 'p': 'percentile', 'm': 'model_name', 'r': 'region'}
        header = ['experiment_type', 'data_name', 'model_experiment_type', 'model_data_name',
            'percentile', 'window_size', 'model_name'] + self.metrics
        for dirname in os.listdir('metrics/cross/{},{}'.format(self.experiment_type, self.data_name)):
            model_experiment_type, model_data_name = dirname.split(',')
            for filename in glob.glob('metrics/cross/{},{}/{}/*.h5'.format(self.experiment_type, self.data_name, dirname)):
                d = parse_filename(filename, name_dict)
                if d['region'] != self.region:
                    continue
                f = h5py.File(filename, 'r')
                record = [self.experiment_type, self.data_name,
                    model_experiment_type, model_data_name,
                    d['percentile'], d['window_size'], d['model_name']]
                grp = f['metrics']
                for metric in self.metrics:
                    record.append(str(grp[metric][()]))
                records.append(record)
        self.logger.info('save file: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        with open(self.outfile, 'w') as f:
            f.write('\t'.join(header) + '\n')
            for record in records:
                f.write('\t'.join(record) + '\n')

class SelectModel(CommandLineTool):
    arguments = [Argument('metric_file', type=str, required=True, help='A table generated by MetricTable'),
        Argument('outfile', short_opt='-o', type=str, required=False, help='parameters of best models in JSON format'),
        Argument('num', short_opt='-n', type=int, default=1,
            help='maximum number of models to select for each dataset. 0 for all models.'),
        Argument('metric', type=str, default='accuracy')]
    def __call__(self):
        import pandas as pd
        import json
        metric_table = pd.read_table(self.metric_file)
        if self.num <= 0:
            self.num = metric_table.shape[0]
        else:
            self.num = min(self.num, metric_table.shape[0])
        selected = metric_table.sort_values('accuracy', ascending=False).iloc[:self.num, :]
        if self.outfile is not None:
            paramlist = []
            for index, row in  selected.iterrows():
                paramlist.append(row.to_dict())
            prepare_output_file(self.outfile)
            with open(self.outfile, 'w') as f:
                json.dump(paramlist, f, indent=2)
        print selected

class CompareDeepfold1DWithKnown(CommandLineTool):
    arguments = [Argument('infile', type=str, required=True, help='output file of PredictDeepfold1D or a directory'),
        Argument('outfile', type=str, required=True, help='output plot file'),
        Argument('max_plots', type=int, default=30, help='maximum number of sequences to plot'),
        Argument('max_length', type=int, default=200)]
    def __call__(self):
        import pandas as pd
        import_matplotlib()

        if os.path.isdir(self.infile):
            df = []
            n = 0
            for filename in os.listdir(self.infile):
                df.append(pd.read_table('{}/{}'.format(self.infile, filename)))
                n += 1
                if n > self.max_plots:
                    break
            df = pd.concat(df)
        else:
            df = pd.read_table(self.infile)
        prepare_output_file(self.outfile)
        self.logger.info('save file: {}'.format(self.outfile))
        with PdfPages(self.outfile) as pdf:
            n_plots = 0
            for name, sub_df in df.groupby('name'):
                fig, ax = plt.subplots(figsize=(15, 1.5))
                length = sub_df.shape[0]
                if length > self.max_length:
                    start = length/2 - self.max_length/2
                    sub_df = sub_df.iloc[start:(start + self.max_length), :]
                ax.plot(sub_df['position'], sub_df['pred'], 'b-', label='prediction')
                ax.plot(sub_df['position'], sub_df['true'], 'k-', label='known')
                ax.legend(loc='upper right')
                ax.set_ylim(-0.1, 1.1)
                ax.set_title(name)
                plt.tight_layout()
                pdf.savefig(fig)
                plt.close(fig)
                n_plots += 1
                if n_plots >= self.max_plots:
                    break

class CompareCtFiles(CommandLineTool):
    arguments = [Argument('indir1', type=str, required=True, help='directory containing ct files'),
        Argument('indir2', type=str, required=True, help='directory containing ct files'),
        Argument('group_name1', type=str, default='Group 1'),
        Argument('group_name2', type=str, default='Group 2'),
        Argument('outfile', type=str, required=True, help='output plot file'),
        Argument('max_plots', type=int, default=20, help='maximum number of sequences to plot'),
        Argument('random', action='store_true', help='randomly select structures to plot'),
        Argument('max_length', type=int, default=200)]
    def __call__(self):
        import_matplotlib()
        import numpy as np

        names1 = map(lambda x: os.path.splitext(x)[0], os.listdir(self.indir1))
        names2 = map(lambda x: os.path.splitext(x)[0], os.listdir(self.indir2))

        prepare_output_file(self.outfile)
        self.logger.info('save file: {}'.format(self.outfile))
        with PdfPages(self.outfile) as pdf:
            n_plots = 0
            for name in names1:
                if name not in names2:
                    continue
                name1, seq1, pairs1 = read_ct('{}/{}.ct'.format(self.indir1, name))
                name2, seq2, pairs2 = read_ct('{}/{}.ct'.format(self.indir2, name))
                fig, axes = plt.subplots(nrows=2, figsize=(12, 4), sharex=True)
                length = len(seq1)
                x = np.arange(length)
                pairs1 = np.asarray(pairs1, dtype='int64')
                pairs1[pairs1 > 1] = 1
                pairs2 = np.asarray(pairs2, dtype='int64')
                pairs2[pairs2 > 1] = 1
                if length > self.max_length:
                    start = length/2 - self.max_length/2
                    pairs1 = pairs1[start:(start + self.max_length)]
                    pairs2 = pairs2[start:(start + self.max_length)]
                    x = x[start:(start + self.max_length)]
                axes[0].bar(x, pairs1, label=self.group_name1, color='b', edgecolor='w')
                axes[0].set_title('{}({})'.format(name, self.group_name1))
                axes[1].bar(x, pairs2, label=self.group_name1, color='b', edgecolor='w')
                axes[1].set_title('{}({})'.format(name, self.group_name2))
                pdf.savefig(fig)
                n_plots += 1
                if n_plots >= self.max_plots:
                    break

class ScoreStructure(CommandLineTool):
    description = 'Compare predicted and known structures in CT format and calculate the metrics'
    arguments = [Argument('true_file', type=str, required=True, help='CT format'),
        Argument('pred_file', type=str, required=True, help='CT format'),
        Argument('outfile', short_opt='-o', type=str),
        Argument('exact', action='store_true', help='count exact pairs')]
    def score_ct(self, true_ct_file, pred_ct_file):
        ct_true = read_ct(true_ct_file)
        ct_pred = read_ct(pred_ct_file)
        scores = score_structure(make_pair_list(ct_true[2]),
            make_pair_list(ct_pred[2]), exact=self.exact)
        scores['length'] = len(ct_pred[1])
        return scores

    def __call__(self):
        keys = ['length', 'sensitivity', 'ppv', 'tp_in_true', 'true_pairs', 'tp_in_pred', 'pred_pairs']
        fout = sys.stdout
        if self.outfile is not None:
            self.logger.info('save file: {}'.format(self.outfile))
            prepare_output_file(self.outfile)
            fout = open(self.outfile, 'w')
        if os.path.isdir(self.true_file) and os.path.isdir(self.pred_file):
            names = [os.path.splitext(a)[0] for a in os.listdir(self.pred_file)]
            fout.write('\t'.join(['name'] + keys) + '\n')
            for name in names:
                #self.logger.debug('read ct: {}'.format(name))
                scores = self.score_ct('{}/{}.ct'.format(self.true_file, name),
                    '{}/{}.ct'.format(self.pred_file, name))
                fout.write('\t'.join([name] + map(str, map(lambda x: scores[x], keys))) + '\n')
        else:
            scores = self.score_ct(self.true_file, self.pred_file)
            name = os.path.splitext(self.pred_file)[0]
            fout.write('\t'.join(['name'] + keys) + '\n')
            fout.write('\t'.join([ct_true[0]] + map(str, map(lambda x: scores[x], keys))) + '\n')
        if self.outfile is not None:
            fout.close()

class CompareStructurePredictionMetrics(CommandLineTool):
    description = 'Plot the difference between score metrics of two methods'
    arguments = [Argument('infile1', type=str, required=True, help='output file of ScoreStructure'),
        Argument('infile2', type=str, required=True, help='output file of ScoreStructure'),
        Argument('outfile', short_opt='-o', type=str, help='output plot file'),
        Argument('metric', type=str, default='sensitivity'),
        Argument('title', type=str, default='Distribution of {metric} {compare_method}'),
        Argument('compare_method', type=str, default='difference')]
    def __call__(self):
        import pandas as pd
        import_matplotlib()
        table1 = pd.read_table(self.infile1)
        table2 = pd.read_table(self.infile2)
        merged = pd.merge(table1, table2, on='name')
        diff = merged['{}_x'.format(self.metric)] - merged['{}_y'.format(self.metric)]
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.hist(diff, bins=50)
        ax.set_title(self.title.format(metric=self.metric, compare_method=self.compare_method,
            mean=diff.mean(), median=diff.median()))
        ax.set_xlim(-1, 1)
        self.logger.info('save plot file: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        plt.savefig(self.outfile)

class DeepfoldDatasetStatistics(CommandLineTool):
    description = 'Basic statistics (e.g. number of samples) for a deepfold dataset'
    arguments = [Argument('experiment_type', type=str, required=True),
        Argument('data_name', type=str, required=True),
        Argument('outfile', short_opt='-o', required=True)]
    def number_of_samples(self):
        import h5py
        import glob
        name_dict = {'d': 'data_name', 'w': 'window_size', 'p': 'percentile', 'm': 'model_name', 'r': 'region'}
        header = ['experiment_type', 'data_name', 'region', 'window_size', 'percentile', 'n_train', 'n_test']
        records = []
        for filename in glob.glob('data/{}/{}/deepfold/*.h5'.format(self.experiment_type, self.data_name)):
            d = parse_filename(filename, name_dict)
            f = h5py.File(filename, 'r')
            records.append((self.experiment_type, self.data_name, d['region'], d['window_size'], d['percentile'],
                f['y_train'].shape[0], f['y_test'].shape[0]))
        self.logger.info('save file: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        with open(self.outfile, 'w') as f:
            f.write('\t'.join(header))
            f.write('\n')
            for record in records:
                f.write('\t'.join(map(str, record)))
                f.write('\n')

    def __call__(self):
        self.number_of_samples()

class CompareDeepfold1DMetrics(CommandLineTool):
    description = 'Compare 1D structure prediction metrics grouped by dataset'
    arguments = [Argument('infile', short_opt='-i', type=str,
        help='metric table generated by MetricTable command'),
        Argument('outfile', short_opt='-o', type=str)]
    def __call__(self):
        import_matplotlib()
        import pandas as pd
        import numpy as np
        df = pd.read_table(self.infile)
        summary = []
        for name, subdf in df.groupby(['model_name']):
            i = subdf['roc_auc'].idxmax()
            summary.append(subdf.ix[i, :])
        summary = pd.concat(summary, axis=1).T
        self.logger.info('save summary table: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        summary.to_csv(self.outfile, index=False, sep='\t')

class GenomicDataDistribution(CommandLineTool):
    description = 'Plot distribution of values in GenomicData files'
    arguments = [Argument('infile', short_opt='-i', type=str, required=True,
            help='input file in GenomicData format'),
        Argument('feature', type=str, required=True, help='the feature to plot'),
        Argument('outfile', short_opt='-o', type=str, required=True),
        Argument('xlabel', type=str, default='Values'),
        Argument('ylabel', type=str, default='Counts'),
        Argument('weight', type=float, default=1),
        Argument('title', type=str)]
    def __call__(self):
        import_matplotlib()
        import numpy as np
        data = GenomicData(self.infile, feature_names=[self.feature])
        fig, ax = plt.subplots(figsize=(4, 4))
        valid_data = data.features[self.feature][np.logical_not(np.isnan(data.features[self.feature]))]
        ax.hist(valid_data, weights=np.full(len(valid_data), self.weight), bins=20, color='#808080')
        ax.set_xlabel(self.xlabel)
        ax.set_ylabel(self.ylabel)
        #ax.set_yticks(np.arange(len(counts)), map(lambda x: '%.1f'%x, counts.astype('float')*1e-6))
        plt.tight_layout()
        if self.title:
            ax.set_title(self.title)
        self.logger.info('save figure: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        plt.savefig(self.outfile)

class SampleSizeTable(CommandLineTool):
    description = 'Generate a table of the number of samples in the Deepfold dataset and original dataset'
    arguments = [Argument('indir', type=str, required=True,
            help='directory containing GenomicData files with path <dataset>/<region>.h5'),
        Argument('feature', type=str),
        Argument('outfile', short_opt='-o', required=True),
        Argument('percentile', type=float),
        Argument('region', type=str)]
    def __call__(self):
        import pandas as pd
        import h5py
        import numpy as np
        regions = ['all', '3UTR', '5UTR', 'lncRNA', 'CDS', 'ncRNA', 'miRNA']
        if self.region:
            regions = [self.region]
        records = []
        for dataset in os.listdir(self.indir):
            for region in regions:
                data_file = os.path.join(self.indir, dataset, '%s.h5'%region)
                if not os.path.isfile(data_file):
                    self.logger.warn('GenomicData file {} does not exist'.format(data_file))
                    continue
                data = GenomicData(data_file)
                if not self.feature:
                    feature = data.features.keys()[0]
                    #self.logger.info('use the default feature %s because --feature is not given')
                else:
                    feature = self.feature
                if self.percentile is not None:
                    data_valid = data.features[feature][np.logical_not(np.isnan(data.features[feature]))]
                    cutoff1 = np.percentile(data_valid, self.percentile)
                    cutoff2 = np.percentile(data_valid, 100 - self.percentile)
                    n_samples = np.logical_or(data_valid <= cutoff1, data_valid >= cutoff2).sum()
                else:
                    n_samples = len(data.features[feature]) - np.isnan(data.features[feature]).sum()
                records.append((dataset, region, n_samples))
        df = pd.DataFrame.from_records(records, columns=['dataset', 'region', 'n_samples'])
        print df.to_csv(sep='\t', index=False)

class DeepfoldSampleSizeTable(CommandLineTool):
    description = 'Generate a table of the number of samples in the Deepfold dataset and original dataset'
    arguments = [Argument('indirs', short_opt='-i', required=True, nargs='+'),
        Argument('feature', type=str),
        Argument('deepfold_dataset', type=str, required=False, default='r={},p=5,w=100.h5'),
        Argument('outfile', short_opt='-o', required=True),
        Argument('percentile', type=float, default=5),
        Argument('region', type=str),
        Argument('sequence_file', type=str, help='FASTA file')]

    def __call__(self):
        import pandas as pd
        import numpy as np
        import h5py
        regions = ['all', '3UTR', '5UTR', 'lncRNA', 'CDS']
        records = []
        for indir in self.indirs:
            for region in regions:
                deepfold_dataset = 'r={},p=5,w=100.h5'.format(region)
                data = GenomicData(os.path.join(indir, '{}.h5'.format(region)))
                if not self.feature:
                    feature = data.features.keys()[0]
                else:
                    feature = self.feature
                n_samples_total = len(data.features[feature]) - np.isnan(data.features[feature]).sum()
                f = h5py.File(os.path.join(indir, 'deepfold', deepfold_dataset), 'r')
                n_samples_train = f['X_train'].shape[0]
                n_samples_test = f['X_test'].shape[0]
                f.close()
                records.append((indir, deepfold_dataset, region, n_samples_total, n_samples_train, n_samples_test))
        df = pd.DataFrame.from_records(records, columns=('dataset', 'deepfold_dataset', 'region', 'n_samples_total', 'n_samples_train', 'n_samples_test'))
        self.logger.info('save file: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        df.to_csv(self.outfile, sep='\t', index=False)

class LogRegWeights(CommandLineTool):
    description = 'Plot weights of a Logistic regression model as lines'
    arguments = [Argument('infile', short_opt='-i', type=str, required=True,
            help='model file in HDF5 format'),
        Argument('outfile', short_opt='-o', type=str, required=True),
        Argument('alphabet', type=str, default='ATCG')]

    def __call__(self):
        import h5py
        import numpy as np
        import_matplotlib()

        model_weights = h5py.File(self.infile, 'r')['/model_weights/dense_1/dense_1/kernel:0'][:]
        window_size = model_weights.shape[0]/len(self.alphabet)
        offset = (window_size + 1)/2
        model_weights = model_weights.reshape((window_size, 4))
        fig, ax = plt.subplots(figsize=(20, 4))
        for i in range(len(self.alphabet)):
            ax.plot(np.arange(window_size), model_weights[:, i], '-', label=self.alphabet[i])
        ax.set_xticks(np.arange(window_size, step=5))
        ax.set_xlim(0, window_size)
        ax.set_ylabel('Weight')
        ax.set_xlabel('Position')
        ax.set_xticks(np.arange(window_size), minor=True)
        ax.set_xticks(np.arange(offset%5, window_size + 1, step=5))
        ax.set_xticklabels(np.arange(offset%5, window_size + 1, step=5) - window_size/2)
        ax.set_ylim(-2, 2)
        ax.legend()
        plt.tight_layout()
        self.logger.info('save figure: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        plt.savefig(self.outfile, dpi=150, bbox_inches='tight')

class RocCurve(CommandLineTool):
    description = 'Plot ROC curves of different methods'
    arguments = [Argument('indir', short_opt='-i', type=str, required=True,
            help='directory containing the metric files in HDF5 format'),
        Argument('outfile', type=str, required=True),
        Argument('region', type=str, help='filter files by region'),
        Argument('model', type=str, help='filter files by model'),
        Argument('bykey', type=str, required=True, help='the key to compare by'),
        Argument('xkey', type=str, help='key for the x axis'),
        Argument('plot_type', type=str, default='roc_curve', choices=('auc_lines', 'roc_curve')),
        Argument('title', type=str, default='Receiver operating characteristic of different models')]
    def parse_filename(self, filename):
        d = {}
        expand_names = {'r': 'region', 'm': 'model', 'w': 'window_size', 'p': 'percentile'}
        for item in os.path.splitext(os.path.basename(filename))[0].split(','):
            key, val = item.split('=')
            d[expand_names[key]] = val
        return d

    def auc_lines(self, auc, params):
        import numpy as np
        fig, ax = plt.subplots(figsize=(5, 4))
        for keyval in params.keys():
            if self.xkey == 'window_size':
                window_sizes = [int(d['window_size']) for d in params[keyval]]
                sorted_index = np.argsort(window_sizes)
                auc[keyval] = map(lambda i: auc[keyval][i], sorted_index)
                params[keyval] = map(lambda i: params[keyval][i], sorted_index)
                ax.set_xticks(np.arange(len(window_sizes)))
                ax.set_xticklabels(sorted(window_sizes))
                ax.set_xlabel('Window Size')
            ax.plot(np.arange(len(window_sizes)), auc[keyval], lw=1.5, label=keyval)
        ax.set_title(self.title)
        ax.set_ylabel('AUROC')
        ax.set_ylim(0.75, 1)
        ax.legend(loc='lower right')
        plt.tight_layout()
        self.logger.info('save figure: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        plt.savefig(self.outfile)

    def roc_curve(self, fpr, tpr, params):
        import numpy as np
        fig, ax = plt.subplots(figsize=(5, 5))
        plt.rcParams['font.size'] = 11
        plt.rcParams['legend.fontsize'] = 11
        ax.plot([0, 1], [0, 1], 'k--')
        for keyval in params.keys():
            best_index = np.argmax(auc[keyval])
            ax.plot(fpr[keyval][best_index], tpr[keyval][best_index],
                label='{} (AUC = {:.3f})'.format(keyval, auc[keyval][best_index]))
        ax.set_xlabel('False Positive Rate')
        ax.set_ylabel('True Positive Rate')
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1.1)
        ax.set_xticks(np.linspace(0, 1, 6))
        ax.set_yticks(np.linspace(0, 1, 6))
        ax.legend(loc='lower right')
        ax.set_title(self.title)
        plt.tight_layout()

        self.logger.info('save figure: {}'.format(self.outfile))
        prepare_output_file(self.outfile)
        plt.savefig(self.outfile)

    def __call__(self):
        import h5py
        import_matplotlib()
        from sklearn.metrics import roc_curve, roc_auc_score
        from collections import defaultdict
        fpr = defaultdict(list)
        tpr = defaultdict(list)
        auc = defaultdict(list)
        params = defaultdict(list)
        for filename in os.listdir(self.indir):
            d = self.parse_filename(filename)
            keyval = d[self.bykey]
            if (self.region is not None) and (d.get('region') != self.region):
                continue
            if (self.model is not None) and (d.get('model') != self.model):
                continue
            f = h5py.File(os.path.join(self.indir, filename), 'r')
            y_true = f['y_true'][:]
            y_pred = f['y_pred'][:]
            f.close()
            fpr_, tpr_, thresholds = roc_curve(y_true, y_pred)
            fpr[keyval].append(fpr_)
            tpr[keyval].append(tpr_)
            auc[keyval].append(roc_auc_score(y_true, y_pred))
            params[keyval].append(d)

        if self.plot_type == 'auc_lines':
            self.auc_lines(auc, params)
        elif self.plot_type == 'roc_curve':
            self.roc_curve(fpr, tpr, auc, params)

class DrawRnaStructureWithValues(CommandLineTool):
    description = 'Draw RNA secondary structure with color mapping from a list of values'
    arguments = [Argument('varna_path', type=str, required=True, help='path to VARNAvX-Y.jar'),
        Argument('ct_file', type=str, required=True),
        Argument('value_file', type=str, required=True),
        Argument('outfile', type=str, required=True),
        Argument('value_format', type=str, default='rme', choices=('rme',))]
    def __call__(self):
        import subprocess
        from formats import read_rme, read_ct
        values = read_rme(self.value_file).values()[0]
        title, seq, pairs = read_ct(self.ct_file)
        values_fillna = []
        for i in range(len(seq)):
            if i in values:
                values_fillna.append(values[i])
            else:
                values_fillna.append(0.5)
        colormap = ';'.join(map(lambda x: '%.3f'%x, values_fillna))
        prepare_output_file(self.outfile)
        cmdline = ['java', '-cp', self.varna_path,
            'fr.orsay.lri.varna.applications.VARNAcmd',
            '-i', self.ct_file, '-resolution', '5.0',
            '-colorMapStyle', 'rocknroll',
            '-colorMap', colormap, '-o', self.outfile]
        self.logger.info('execute: {}'.format(' '.join(cmdline)))
        p = subprocess.Popen(cmdline)
        p.wait()

class CorrelationBetweenBumhmmAndIcshape(CommandLineTool):
    description = 'Calculate the correlation between BUMHMM posteriors and icSHAPE scores'
    arguments = [Argument('bumhmm_file', type=str, required=True),
        Argument('icshape_file', type=str, required=True),
        Argument('prefix', short_opt='-o', type=str, required=True)]
    def __call__(self):
        import_matplotlib()
        import numpy as np
        import h5py
        import pandas as pd
        from sklearn.metrics import roc_auc_score
        from scipy.stats import pearsonr, spearmanr, ttest_ind

        def normalized_mutual_information(p, epsilon=1e-12):
            p = p + epsilon
            p /= p.sum()
            px = p.sum(axis=1)
            py = p.sum(axis=0)
            pxpy = np.dot(px.reshape(-1, 1), py.reshape(1, -1))
            Hxy = np.sum(p*np.log(p/pxpy))
            Hx = np.sum(px*np.log(px))
            Hy = np.sum(py*np.log(py))
            return Hxy/np.sqrt(Hx*Hy)

        self.logger.info('read BUMHMM posteriors: ' + self.bumhmm_file)
        bumhmm = GenomicData(self.bumhmm_file, feature_names=['bumhmm'])
        self.logger.info('read icSHAPE scores: ' + self.icshape_file)
        icshape = GenomicData(self.icshape_file, feature_names=['icshape'])
        names, counts = np.unique(np.concatenate((bumhmm.names, icshape.names)), return_counts=True)
        common_names = names[counts >= 2]

        metrics = ('roc_auc', 't_test_p', 'pearsonr', 'spearmanr', 'normalized_mi')
        correlation = {}
        for metric in metrics:
            correlation[metric] = np.full(len(common_names), np.nan)
        values_bumhmm_selected = []
        values_icshape_selected = []
        for i, name in enumerate(common_names):
            values_icshape = icshape.feature('icshape', name)
            values_bumhmm = bumhmm.feature('bumhmm', name)
            valid_index = np.nonzero(np.logical_not(np.logical_or(np.isnan(values_icshape), np.isnan(values_bumhmm))))[0]
            values_icshape = values_icshape[valid_index]
            values_bumhmm = values_bumhmm[valid_index]
            values_bumhmm_binary = (values_bumhmm > 0.5).astype('int32')

            if values_bumhmm_binary.sum() in (0, len(values_bumhmm_binary)):
                self.logger.warn('ignoring %s because only one class is defined by the BUMHMM posteriors'%name)
                continue
            if len(values_icshape_selected) < 10:
                values_icshape_selected.append(values_icshape)
                values_bumhmm_selected.append(values_bumhmm)


            correlation['roc_auc'][i] = roc_auc_score(values_bumhmm_binary, values_icshape)
            a = values_icshape[values_bumhmm_binary == 0]
            b = values_icshape[values_bumhmm_binary == 1]
            correlation['t_test_p'][i] = ttest_ind(a, b)[1]
            correlation['pearsonr'][i] = pearsonr(values_icshape, values_bumhmm)[0]
            correlation['spearmanr'][i] = spearmanr(values_icshape, values_bumhmm)[0]

            bins = np.linspace(0.0, 1.0, 21)
            bin_index = np.digitize(values_icshape, bins) - 1
            pxy = np.empty((2, 20), dtype='float64')
            pxy[0] = np.histogram(a, bins=bins)[0]
            pxy[1] = np.histogram(b, bins=bins)[0]
            correlation['normalized_mi'][i] = normalized_mutual_information(pxy)

        for metric in correlation:
            correlation[metric][np.isinf(correlation[metric])] = np.nan
        df = pd.DataFrame(correlation)
        df['seqname'] = common_names
        df = df.dropna(axis=0, how='any')

        table_file = self.prefix + '.txt'
        self.logger.info('save correlations to file: ' + table_file)
        prepare_output_file(table_file)
        df.to_csv(table_file, sep='\t', index=False)

        plot_file = self.prefix + '.pdf'
        self.logger.info('save plot file: ' + plot_file)
        with PdfPages(plot_file) as pdf:
            values_bumhmm_selected = np.concatenate(values_bumhmm_selected)
            values_icshape_selected = np.concatenate(values_icshape_selected)
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.scatter(values_icshape_selected, values_bumhmm_selected, s=1, edgecolor='none')
            ax.set_xlabel('icSHAPE scores')
            ax.set_ylabel('BUMHMM posterior probabilities')
            ax.set_title('icSHAPE scores and BUMHMM posteriors')
            pdf.savefig(fig)
            plt.clf()
            plt.close(fig)

            for metric in metrics:
                fig, ax = plt.subplots(figsize=(8, 6))
                if metric in ('t_test_p'):
                    ax.hist(np.log(df[metric] + 1e-12), bins=50)
                else:
                    ax.hist(df[metric], bins=50)
                ax.set_title('Correlation between icSHAPE scores and BUMHMM (%s)'%metric)
                ax.set_xlabel(metric)
                ax.set_ylabel('Counts')

                plt.tight_layout()
                pdf.savefig(fig)
                plt.clf()
                plt.close(fig)

class BumhmmExamples(CommandLineTool):
    arguments = [Argument('posterior_file', short_opt='-i', type=str, required=True,
            help='BUMHMM output file'),
        Argument('bumhmm_input_file', type=str, required=True),
        Argument('outfile', short_opt='-o', type=str, required=True,
            help='output file')]
    def __call__(self):
        import h5py
        import numpy as np
        import_matplotlib()
        from scipy import signal

        self.logger.info('read BUMHMM file: ' + self.posterior_file)
        posteriors = h5py.File(self.posterior_file, 'r')['posteriors'][:]
        self.logger.info('read BUMHMM input file: ' + self.bumhmm_input_file)
        f = h5py.File(self.bumhmm_input_file, 'r')
        start = f['start'][:]
        end = f['end'][:]
        name = f['name'][:]
        f.close()

        self.logger.info('open pdf file: ' + self.outfile)
        prepare_output_file(self.outfile)
        plt.rcParams['axes.labelsize'] = 'small'
        plt.rcParams['xtick.labelsize'] = 'x-small'
        plt.rcParams['ytick.labelsize'] = 'x-small'
        plt.rcParams['axes.titlesize'] = 'small'

        window_size = 300
        window = np.ones(300)
        with PdfPages(self.outfile) as pdf:
            n_plots = 0
            while n_plots < 50:
                i = np.random.choice(len(name))
                if end[i] - start[i] < window_size:
                    continue
                na_fraction = signal.convolve(np.isnan(posteriors[start[i]:end[i]]).astype('float'), window, mode='valid')/window_size
                valid_windows = np.nonzero(na_fraction < 0.75)[0]
                if len(valid_windows) <= 0:
                    continue

                self.logger.info('plot %s'%name[i])
                offset = valid_windows[0]
                length = min(window_size, end[i] - start[i] - offset)
                index = np.arange(start[i] + offset, start[i] + length + offset)
                posteriors_fillna = posteriors[index]
                na_index = np.nonzero(np.isnan(posteriors_fillna))[0]
                posteriors_fillna[na_index] = -0.1
                color = np.full(length, '#0000ff', dtype='S7')
                color[na_index] = '#999999'

                x = np.arange(offset, offset + length)
                fig, ax = plt.subplots(figsize=(15, 1.5))

                ax.bar(x, posteriors_fillna, color=color, edgecolor='none')
                ax.set_xlim(0, length)
                ax.set_ylim(-0.1, 1)
                ax.set_title('BUMHMM posteriors (%s)'%name[i])

                plt.tight_layout()
                pdf.savefig(fig)
                plt.clf()
                plt.close(fig)

                n_plots += 1

class CompareBumhmmWithCoverageAndDropoff(CommandLineTool):
    arguments = [Argument('posterior_file', short_opt='-i', type=str, required=True,
            help='BUMHMM output file'),
        Argument('bumhmm_input_file', type=str, required=True),
        Argument('outfile', short_opt='-o', type=str, required=True,
            help='output file')]
    def __call__(self):
        import h5py
        import numpy as np
        import_matplotlib()

        self.logger.info('read BUMHMM file: ' + self.posterior_file)
        posteriors = h5py.File(self.posterior_file, 'r')['posteriors'][:]
        self.logger.info('read BUMHMM input file: ' + self.bumhmm_input_file)
        f = h5py.File(self.bumhmm_input_file, 'r')
        start = f['start'][:]
        end = f['end'][:]
        name = f['name'][:]
        coverage = f['coverage'][:]
        sample_name = f['sample_name'][:]
        replicate = f['replicate'][:]
        dropoff_count = f['dropoff_count'][:]
        f.close()

        self.logger.info('open pdf file: ' + self.outfile)
        prepare_output_file(self.outfile)
        plt.rcParams['axes.labelsize'] = 'small'
        plt.rcParams['xtick.labelsize'] = 'x-small'
        plt.rcParams['ytick.labelsize'] = 'x-small'
        plt.rcParams['axes.titlesize'] = 'small'

        with PdfPages(self.outfile) as pdf:
            for i in np.random.choice(len(name), size=10):
                self.logger.info('plot %s'%name[i])
                length = min(300, end[i] - start[i] - 50)
                index = np.arange(start[i] + 50, start[i] + length + 50)
                x = np.arange(50, 50 + length)
                fig, axes = plt.subplots(1 + 2*coverage.shape[0], figsize=(15, 2 + 2*coverage.shape[0]), sharex=True)

                posteriors_fillna = posteriors[index]
                color = np.asarray(['#999999' if np.isnan(a) else '#0000ff' for a in posteriors_fillna])
                posteriors_fillna[np.isnan(posteriors_fillna)] = -0.05

                axes[0].bar(x, posteriors_fillna, color=color, edgecolor='none')
                axes[0].set_xlim(0, length)
                axes[0].set_ylim(-0.1, 1)
                axes[0].set_title('BUMHMM posteriors (%s)'%name[i])
                for j in range(coverage.shape[0]):
                    axes[2*j + 1].bar(x, dropoff_count[j, index].astype('float')/coverage[j, index], edgecolor='none')
                    axes[2*j + 1].set_title('Dropoff rate of %s (%s)'%(replicate[j], sample_name[j]))
                    axes[2*j + 1].set_ylim(0, 0.5)

                    axes[2*j + 2].bar(x, coverage[j, index], edgecolor='none')
                    axes[2*j + 2].set_title('Coverage of %s (%s)'%(replicate[j], sample_name[j]))
                    axes[2*j + 1].set_ylim(0, 0.5)
                plt.tight_layout()
                pdf.savefig(fig)
                plt.clf()
                plt.close(fig)


class BaseDistributionByBin(CommandLineTool):
    description = 'Calculate base distribution for each bin between percentiles'
    arguments = [Argument('infile', short_opt='-i', type=str, required=True,
                help='a dataset in GenomicData format'),
        Argument('sequence_file', type=str, required=True, help='FASTA file'),
        Argument('prefix', short_opt='-o', type=str, required=True),
        Argument('bins', type=int, default=10, help='number of bins for percentiles'),
        Argument('bin_method', type=str, default='percentile', choices=('percentile', 'value'),
                 help='how to divide the values into bins of equal width'),
        Argument('alphabet', type=str, default='ATCG'),
        Argument('offset', type=int, default=0,
                 help="offset from the modified base (from 5' to 3')"),
        Argument('feature', type=str)]

    def __call__(self):
        from formats import read_fasta
        from tqdm import tqdm
        import numpy as np
        import pandas as pd
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt

        self.logger.info('read sequence file: ' + self.sequence_file)
        sequences = dict(read_fasta(self.sequence_file))
        self.logger.info('read input file: ' + self.infile)
        data = GenomicData(self.infile)
        if self.feature is None:
            if len(data.features.keys()) == 1:
                self.feature = data.features.keys()[0]
            else:
                raise ValueError('multiple features found in the input file and the feature is not specified')

        # freqs[i]['A']: frequency of A in bin i
        freqs = []
        scores_all = data.features[self.feature]
        scores_avail = scores_all[np.logical_not(np.isnan(scores_all))]

        self.logger.info('use bin method: %s'%self.bin_method)
        if self.bin_method == 'percentile':
            qs = np.arange(1, self.bins + 1, dtype='float')*100.0/self.bins
            percentiles = np.zeros(self.bins + 1, dtype='float')
            percentiles[0] = scores_avail.min() - 1e-6
            for i in range(1, self.bins):
                percentiles[i] = np.percentile(scores_avail, qs[i - 1])
            percentiles[self.bins] = scores_avail.max() + 1e-6
        elif self.bin_method == 'value':
            density, percentiles = np.histogram(scores_avail, bins=self.bins, density=True)
            qs = np.cumsum(density)*100.0
            percentiles[0] -= 1e-6
            percentiles[-1] += 1e-6
        else:
            raise ValueError('unknown bin method: %s'%self.bin_method)

        for i in range(self.bins):
            d = {a:0 for a in self.alphabet}
            freqs.append(d)
        self.logger.info('count base frequencies with offset %d'%self.offset)
        for name in tqdm(data.names):
            scores_ts = data.feature(self.feature, name)
            avail_ind = np.nonzero(np.logical_not(np.isnan(scores_ts)))[0]
            seq_ts = np.frombuffer(sequences[name], dtype='S1')
            avail_ind += self.offset
            if self.offset > 0:
                avail_ind = avail_ind[avail_ind < len(seq_ts)]
            elif self.offset < 0:
                avail_ind = avail_ind[avail_ind >= 0]
            scores_avail_ts = scores_ts[avail_ind - self.offset]
            seq_avail_ts = seq_ts[avail_ind]
            for i in range(self.bins):
                seq_bin = seq_avail_ts[np.logical_and(scores_avail_ts <= percentiles[i + 1],
                                                      scores_avail_ts > percentiles[i])]
                for a in self.alphabet:
                    freqs[i][a] += np.count_nonzero(seq_bin == a)
        # normalize base frequencies for each percentile
        freq_total = []
        for i in range(self.bins):
            total = sum(freqs[i].values())
            freq_total.append(total)
            for a in self.alphabet:
                if total == 0:
                    freqs[i][a] = 1.0/len(self.alphabet)
                else:
                    freqs[i][a] = float(freqs[i][a])/total
        table_file = self.prefix + '.txt'
        self.logger.info('save results to file: ' + table_file)
        prepare_output_file(table_file)
        df = []
        for i in range(self.bins):
            for a in self.alphabet:
                    df.append((i, qs[i], percentiles[i], a, freq_total[i], freqs[i][a]))
        df = pd.DataFrame.from_records(df,
                                       columns=['bin', 'q', 'percentile', 'base', 'total_freq', 'fraction'])
        df.to_csv(table_file, sep='\t', index=False)
        # plot the distribution
        self.logger.info('create plot')
        plt.rcParams['font.family'] = 'Arial'
        plt.rcParams['axes.labelsize'] = 'medium'
        plt.rcParams['xtick.labelsize'] = 'x-small'
        plt.rcParams['ytick.labelsize'] = 'x-small'
        plt.rcParams['axes.titlesize'] = 'medium'

        fig, ax = plt.subplots(figsize=(7, 5))
        x = np.arange(self.bins)
        xticklabels = ['%.2f'%a for a in percentiles[1:]]
        for base in self.alphabet:
            sub_df = df[df['base'] == base]
            ax.plot(x, sub_df['fraction'], label=base)
        ax.set_xticks(x)
        ax.set_xticklabels(xticklabels)
        ax.set_ylim(0, 1)
        ax.set_xlabel('Values')
        ax.set_ylabel('Base fraction')
        ax.legend()
        plt.tight_layout()

        plot_file = self.prefix + '.pdf'
        self.logger.info('save plot to file: ' + plot_file)
        plt.savefig(plot_file)

if __name__ == '__main__':
    CommandLineTool.from_argv()()
