{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chenxupeng/projects/deepshape\n"
     ]
    }
   ],
   "source": [
    "cd /home/chenxupeng/projects/deepshape/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test random convert to nan\n",
    "with h5py.File('data/new/Spitale_2015_invivo_CDS_0.1') as f:\n",
    "    y = f['y_test'][:]\n",
    "y_f = y.flatten()\n",
    "count = y_f.shape[0]\n",
    "y_f = y.flatten()\n",
    "count = y_f.shape[0]\n",
    "count_convert = int(count*0.1)\n",
    "index_notnan[0]\n",
    "np.random.seed(1111)\n",
    "np.random.shuffle(index_notnan[0])\n",
    "pick_index = index_notnan[0][:count_convert]\n",
    "y_f[pick_index] = np.nan\n",
    "y_f.reshape(-1,128).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_extra_line(f):\n",
    "    \"\"\"Yield an empty line after the last line in the file\n",
    "    \"\"\"\n",
    "    for line in f:\n",
    "        yield line\n",
    "    yield ''\n",
    "def read_fasta(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        name = None\n",
    "        seq = ''\n",
    "        for line in append_extra_line(f):\n",
    "            if line.startswith('>') or (len(line) == 0):\n",
    "                if (len(seq) > 0) and (name is not None):\n",
    "                    yield (name, seq)\n",
    "                if line.startswith('>'):\n",
    "                    name = line.strip()[1:].split()[0]\n",
    "                    seq = ''\n",
    "            else:\n",
    "                if name is None:\n",
    "                    raise ValueError('the first line does not start with \">\"')\n",
    "                seq += line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = dict(read_fasta('data/fasta/CDS.transcript.fa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =h5py.File('/home/chenxupeng/projects/deepshape/data/icSHAPE/Spitale_2015_invitro/CDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "icshape = f['feature/icshape'][:]\n",
    "name = f['name'][:]\n",
    "start = f['start'][:]\n",
    "end = f['end'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12676378,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentile定5或者10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96899998188018799"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(icshape,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_tonan(percentile):\n",
    "    low = np.nanpercentile(icshape,percentile)\n",
    "    high = np.nanpercentile(icshape,100-percentile)\n",
    "    index_nan = np.where(np.logical_and(icshape <high, icshape >low)==1)\n",
    "    icshape_ = np.copy(icshape)\n",
    "    icshape_[index_nan] = np.nan\n",
    "    return icshape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10123 [00:00<?, ?it/s]\u001b[A/home/chenxupeng/apps/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "\n",
      "  0%|          | 2/10123 [00:00<09:12, 18.33it/s]\u001b[A\n",
      "  0%|          | 4/10123 [00:00<09:13, 18.29it/s]\u001b[A\n",
      "  0%|          | 6/10123 [00:00<09:16, 18.20it/s]\u001b[A\n",
      "  0%|          | 8/10123 [00:00<09:43, 17.34it/s]\u001b[A\n",
      "  0%|          | 10/10123 [00:00<10:01, 16.82it/s]\u001b[A\n",
      "  0%|          | 12/10123 [00:00<11:03, 15.23it/s]\u001b[A\n",
      "  0%|          | 19/10123 [00:00<08:29, 19.84it/s]\u001b[A\n",
      "  0%|          | 22/10123 [00:00<08:27, 19.92it/s]\u001b[A\n",
      "  0%|          | 25/10123 [00:01<10:23, 16.19it/s]\u001b[A\n",
      "  0%|          | 28/10123 [00:01<13:03, 12.88it/s]\u001b[A\n",
      "  0%|          | 31/10123 [00:01<11:14, 14.97it/s]\u001b[A\n",
      "  0%|          | 35/10123 [00:02<11:53, 14.14it/s]\u001b[A\n",
      "  0%|          | 38/10123 [00:02<10:29, 16.03it/s]\u001b[A\n",
      "  0%|          | 42/10123 [00:02<08:36, 19.53it/s]\u001b[A\n",
      "  0%|          | 46/10123 [00:02<07:32, 22.25it/s]\u001b[A\n",
      "  0%|          | 49/10123 [00:02<08:23, 20.02it/s]\u001b[A\n",
      "  1%|          | 55/10123 [00:02<06:43, 24.93it/s]\u001b[A\n",
      "  1%|          | 60/10123 [00:02<05:59, 27.96it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-0838e2eb4d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrna_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m128.0\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcoverage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nan_icshape = shape_tonan(5)\n",
    "coverage = 0.1\n",
    "\n",
    "rna_icshape_whole = {}\n",
    "rna_nan_index = {}\n",
    "for i in tqdm(range(name.shape[0])):   #name.shape[0]\n",
    "    rna_name = name[i]\n",
    "    sequence = fasta[rna_name]\n",
    "    shape_score = nan_icshape[start[i]:end[i]]\n",
    "    length = end[i] - start[i] \n",
    "    count = length-128+1\n",
    "    if count >=0:\n",
    "        y = np.zeros([count,130]).astype('S')\n",
    "        index = np.array([])\n",
    "        for j in range(count):\n",
    "            y[j][0] = rna_name\n",
    "            y[j][1] = j\n",
    "            y[j][2:] = shape_score[j:j+128]  \n",
    "            if np.where(y[j][2:] == str(np.nan))[0].shape[0]/128.0 >1 - coverage:\n",
    "                index = np.concatenate((index,np.array([j])))\n",
    "        y = np.delete(y,index,axis =0)\n",
    "        rna_icshape_whole[i] = y\n",
    "        rna_nan_index[i] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 2736.,  2737.,  2738.,  2739.,  2740.,  2741.,  2742.,  2743.,\n",
       "         2744.,  2745.,  2746.,  2747.,  2748.,  2749.,  2750.,  2751.,\n",
       "         2752.,  2753.,  2754.,  2755.,  2756.,  2757.,  2758.,  2759.,\n",
       "         2760.,  2761.,  2762.,  2763.,  2764.,  2765.,  2766.,  2767.,\n",
       "         2768.,  2769.,  2770.,  2771.,  2772.,  2773.,  2774.,  2775.,\n",
       "         2776.,  2777.,  2778.,  2779.,  2780.,  2781.,  2782.,  2783.,\n",
       "         2784.,  2785.,  2786.,  2787.,  2788.,  2789.,  2790.,  2791.,\n",
       "         2792.,  2793.,  2794.,  2795.,  2796.])}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#只需要上一部的key值那些i对应的rna 找fasta！ 一定要对应好！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fasta[fasta.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 1 2 3 =》 one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATGACAGTCCAACCTTCTCCATGGTTTTCCGATCTCAGGCCCATGGCGACCTGCCCTGTCCTGCAGAAGGAGACACTGTTCCGCACAGGCGTCCATGCTTACAGAATCCCTGCTCTGCTCTACCTGAAGAAGCAGAAGACCCTGCTGGCCTTTGCGGAAAAGCGAGCCAGCAAGACGGATGAGCACGCAGAGTTGATTGTCCTGAGAAGAGGAAGCTACAACGAAGCCACCAACCGTGTCAAGTGGCAGCCTGAGGAAGTGGTGACCCAAGCCCAGCTGGAAGGCCACCGCTCCATGAATCCATGTCCCTTGTATGACAAGCAAACAAAGACCCTCTTCCTTTTCTTCATCGCTGTCCCTGGGCGTGTATCAGAACATCATCAGCTCCACACTAAGGTTAATGTCACACGGCTGTGCTGTGTCAGCAGCACTGACCATGGGAGGACCTGGAGCCCCATCCAGGACCTCACAGAGACCACCATTGGCAGCACTCATCAGGAATGGGCCACATTTGCTGTGGGTCCTGGGCATTGTCTGCAGCTGCGGAACCCAGCTGGGAGCCTGCTGGTACCTGCTTATGCCTACCGGAAACTGCACCCTGCTCAGAAGCCTACCCCCTTTGCCTTCTGCTTCATCAGCCTTGACCATGGGCACACATGGAAACTAGGCAACTTTGTGGCTGAAAACTCACTGGAGTGCCAGGTGGCTGAGGTTGGCACTGGAGCTCAGAGGATGGTATATCTCAATGCTAGGAGCTTCCTGGGAGCCAGGGTCCAGGCACAAAGTCCTAATGATGGTCTGGATTTCCAGGACAACCGGGTAGTGAGTAAGCTTGTAGAGCCCCCCCACGGGTGTCATGGAAGTGTGGTTGCCTTCCACAACCCCATCTCTAAGCCACATGCCTTAGACACATGGCTTCTTTATACACACCCTACAGACTCCAGGAATAGAACCAACCTGGGTGTGTACCTAAACCAGATGCCACTAGATCCCACAGCCTGGTCAGAGCCCACCCTGCTGGCCATGGGCATCTGTGCCTACTCAGACTTACAGAACATGGGGCAAGGCCCTGATGGCTCCCCACAGTTTGGGTGTCTGTATGAATCAGGTAACTATGAAGAGATCATTTTCCTCATATTCACCCTGAAGCAAGCTTTCCCCACTGTATTTGATGCCCAG'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onehot(object):\n",
    "    def __init__(self, alphabet='ATCG'):\n",
    "        self.transtable = np.zeros(128, np.int64)\n",
    "        self.transtable[[ord(a) for a in alphabet]] = range(len(alphabet))\n",
    "        self.alphabet = np.frombuffer(alphabet, np.int8)\n",
    "    def encode(self, seq):\n",
    "        seq_int = self.transtable[np.frombuffer(seq, np.int8)]\n",
    "        encoded = np.zeros((len(seq), len(self.alphabet)), np.int8)\n",
    "        encoded[np.r_[:len(seq)], seq_int] = 1\n",
    "        return encoded\n",
    "    def decode(self, a):\n",
    "        return self.alphabet[np.argmax(a, axis=1)].tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = Onehot()\n",
    "encoded = onehot.encode(data)\n",
    "#decoded = onehot.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0:128]\n",
    "#根据同名rna的索引i对应挑选片段  encoded[i:i+128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"start\": shape (10123,), type \"<i8\">"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#以cds的rna 10123条为顺序，一条一条rna来：\n",
    "#每条rna切成128的小段，one hot，这是 128*4\n",
    "#cds 文件怎么找icshape呢？  找到name的position i ,然后start[i] 是起始，end[i]是终止\n",
    "#把这段icshape取出来， length， length -128 +1 为需要截取的次数 count\n",
    "#for i in range(count): 取出y  把rna name 和在rna中的起始位置（i）加到前两维，算index: 用coverage给，如果非nan比例高于coverage的\n",
    "#才予以保留   找到该条rna需要保留的i \n",
    "#然后构造X  X通过i找到起始位点，每次截取128的长度， 128*4  索引为rna name加上从第几个截取\n",
    "#至此一个rna的处理完毕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.sequences = dict(read_fasta(self.sequence_file))\n",
    "        self.data = GenomicData(self.infile)\n",
    "        if not self.feature:\n",
    "            self.feature = self.data.features.keys()[0]\n",
    "        values = self.data.features[self.feature]\n",
    "\n",
    "        if (self.cutoff1 is None) and (self.cutoff2 is None):\n",
    "            values_valid = values[np.logical_not(np.isnan(values))]\n",
    "            self.cutoff1 = np.percentile(values_valid, self.percentile)\n",
    "            self.cutoff2 = np.percentile(values_valid, 100 - self.percentile)\n",
    "        if self.seed:\n",
    "            self.logger.info('set random seed for numpy: {}'.format(self.seed))\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        self.logger.info('discretize values with cutoffs: {}-{}'.format(self.cutoff1, self.cutoff2))\n",
    "\n",
    "        not_nan_ind = np.nonzero(np.logical_not(np.isnan(values)))[0]\n",
    "        one_ind = not_nan_ind[values[not_nan_ind] >= self.cutoff2]\n",
    "        zero_ind = not_nan_ind[values[not_nan_ind] <= self.cutoff1]\n",
    "        values[:] = np.nan\n",
    "        values[one_ind] = 1\n",
    "        values[zero_ind] = 0\n",
    "\n",
    "        def save_dataset(filename, X_train, y_train, names_train,\n",
    "                X_test, y_test, names_test):\n",
    "            fout = h5py.File(filename, 'w')\n",
    "            fout.create_dataset('names_train', data=names_train)\n",
    "            fout.create_dataset('X_train', data=X_train)\n",
    "            fout.create_dataset('y_train', data=y_train)\n",
    "            fout.create_dataset('names_test', data=names_test)\n",
    "            fout.create_dataset('X_test',  data=X_test)\n",
    "            fout.create_dataset('y_test',  data=y_test)\n",
    "            fout.create_dataset('offset', data=self.offset)\n",
    "            fout.close()\n",
    "\n",
    "        if 0 < self.train_test_split < 1:\n",
    "            n_seqs = len(self.data.names)\n",
    "            n_train = int(n_seqs*self.train_test_split)\n",
    "            train_ind = np.full(n_seqs, False, dtype='bool')\n",
    "            train_ind[np.random.choice(n_seqs, size=n_train, replace=False)] = True\n",
    "            test_ind = np.logical_not(train_ind)\n",
    "            names_train = self.data.names[train_ind]\n",
    "            names_test = self.data.names[test_ind]\n",
    "\n",
    "            if self.balance_kmer:\n",
    "                Xs_train, ys_train, kmers = self.create_dataset(names_train, self.dense_output)\n",
    "                Xs_test, ys_test, kmers = self.create_dataset(names_test, self.dense_output)\n",
    "                for i in range(len(kmers)):\n",
    "                    self.logger.info('number of training/test set for kmer {}: {}/{}'.format(\n",
    "                        kmers[i], Xs_train[i].shape[0], Xs_test[i].shape[0]))\n",
    "                if self.separate:\n",
    "                    for i in range(len(kmers)):\n",
    "                        nuc = self.alphabet[i]\n",
    "                        outfile = os.path.join(self.outfile, kmers[i])\n",
    "                        self.logger.info('save dataset for nucleotide {}: {}'.format(kmers[i], outfile))\n",
    "                        prepare_output_file(outfile)\n",
    "                        save_dataset(outfile, Xs_train[i], ys_train[i], names_train,\n",
    "                            Xs_test[i], ys_test[i], names_test)\n",
    "                else:\n",
    "                    X_train = np.concatenate(Xs_train, axis=0)\n",
    "                    y_train = np.concatenate(ys_train, axis=0)\n",
    "                    ind = np.arange(X_train.shape[0])\n",
    "                    np.random.shuffle(ind)\n",
    "                    X_train = X_train[ind]\n",
    "                    y_train = y_train[ind]\n",
    "\n",
    "                    X_test = np.concatenate(Xs_test, axis=0)\n",
    "                    y_test = np.concatenate(ys_test, axis=0)\n",
    "                    ind = np.arange(X_test.shape[0])\n",
    "                    np.random.shuffle(ind)\n",
    "                    X_test = X_test[ind]\n",
    "                    y_test = y_test[ind]\n",
    "                    self.logger.info('save dataset with balanced nucletide composition: ' + self.outfile)\n",
    "                    prepare_output_file(self.outfile)\n",
    "                    save_dataset(self.outfile, X_train, y_train, names_train,\n",
    "                        X_test, y_test, names_test)\n",
    "            else:\n",
    "                X_train, y_train = self.create_dataset(names_train, self.dense_output)\n",
    "                X_test, y_test = self.create_dataset(names_test, self.dense_output)\n",
    "                self.logger.info('save dataset: ' + self.outfile)\n",
    "                prepare_output_file(self.outfile)\n",
    "                save_dataset(self.outfile, X_train, y_train, names_train,\n",
    "                    X_test, y_test, names_test)\n",
    "        else:\n",
    "            fout = h5py.File(self.outfile)\n",
    "            X, y = self.create_dataset(self.data.names)\n",
    "            fout.create_dataset('X', data=X)\n",
    "            fout.create_dataset('y', data=y)\n",
    "            fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/chenxupeng/projects/deepshape/data/icSHAPE/Spitale_2015_invitro/CDS')\n",
    "end = f['end'][:]\n",
    "icshape = f['feature/icshape'][:]\n",
    "name = f['name'][:]\n",
    "start= f['start'][:]\n",
    "length = end -start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在生成y_test 的时候要标清楚每条的rna来源以及其起始为rna的第几个position\n",
    "\n",
    "#剩下的都是有值的点，已经知道该片段的rna和起始位点了，下面用rna一条一条计算。y_pred和y_true 都对应到rna上\n",
    "#最终的y_true不是CDS里读出来的标注，因为好多位置被转成了nan\n",
    "#同步统计y_true 和y_pred  每条片段的rna对应回去，np.ndarray 一个rna长度的向量\n",
    "#预计新的y_true 每行[rna,origin,128*ichshape]  name指rna name\n",
    "\n",
    "#计算y_true\n",
    "def rna_icshape_true():\n",
    "    position_need = {}\n",
    "    rna_icshape = {}\n",
    "    #每条rna每个位置出现了几次\n",
    "    rna_position = {}\n",
    "    rna_ic_correct = {}\n",
    "    for i in range(name.shape[0]):\n",
    "        #每条rna\n",
    "        rna_icshape[i] = np.zeros([length[i]])\n",
    "        #每个片段看看是否匹配\n",
    "        rna_position[i] = np.array([])\n",
    "        for j in range(y_true.shape[0]):\n",
    "            if y_true[j][0] = name[i]:\n",
    "                origin = y_true[j][1]\n",
    "                #找不是nan的部分,要累加\n",
    "                index = np.where(np.isnan(y_true[2:])=0)[0]\n",
    "                rna_icshape[i][origin:origin+128][index] += y_true[j][2:][index]\n",
    "                #统计赋值的位置\n",
    "                position = np.arange(origin:origin+128)[index]\n",
    "                rna_position[i] = np.concatenate((rna_position[i],position))\n",
    "        #统计第i条rna每个位置分别被加了几次\n",
    "        position_count = np.zeros([length[i]])\n",
    "        unique, counts = numpy.unique(rna_position[i], return_counts=True)\n",
    "        position_count[unique] = counts\n",
    "        #找到position count不是0的位置\n",
    "        index_ = np.where(position_count)[0]\n",
    "        rna_ic_correct[i] = rna_icshape[i][index_].astype('float') / position_count[index_]\n",
    "        rna_ic_correct[i][np.where(rna_ic_correct>=0.5)] =1\n",
    "        rna_ic_correct[i][np.where(rna_ic_correct<0.5)] =0\n",
    "        position_need[i] = index_\n",
    "    return rna_ic_correct,position_need\n",
    "\n",
    "#计算y_test\n",
    "def rna_icshape_pred():\n",
    "    rna_icshape = {}\n",
    "    #每条rna每个位置出现了几次\n",
    "    rna_position = {}\n",
    "    rna_ic_correct = {}\n",
    "    for i in range(name.shape[0]):\n",
    "        #每条rna\n",
    "        rna_icshape[i] = np.zeros([length[i]])\n",
    "        #每个片段看看是否匹配\n",
    "        rna_position[i] = np.array([])\n",
    "        for j in range(y_true.shape[0]):\n",
    "            if y_true[j][0] = name[i]:\n",
    "                origin = y_true[j][1]\n",
    "                #找不是nan的部分,要累加\n",
    "                index = np.where(np.isnan(y_true[2:])=0)[0]\n",
    "                rna_icshape[i][origin:origin+128][index] += y_pred[j][index]\n",
    "                #统计赋值的位置\n",
    "                position = np.arange(origin:origin+128)[index]\n",
    "                rna_position[i] = np.concatenate((rna_position[i],position))\n",
    "        #统计第i条rna每个位置分别被加了几次\n",
    "        position_count = np.zeros([length[i]])\n",
    "        unique, counts = numpy.unique(rna_position[i], return_counts=True)\n",
    "        position_count[unique] = counts\n",
    "        #找到position count不是0的位置\n",
    "        index_ = np.where(position_count)[0]\n",
    "        rna_ic_correct[i] = rna_icshape[i][index_].astype('float') / position_count[index_]\n",
    "        rna_ic_correct[i][np.where(rna_ic_correct>=0.5)] =1\n",
    "        rna_ic_correct[i][np.where(rna_ic_correct<0.5)] =0\n",
    "    return rna_ic_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看下 返回的样子  需要返回一个真正被考虑的位置的index，要不然nan和0都是0，acc肯定大！ \n",
    "#读取 true和pred  以及每条rna需要被考虑的位点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类计算acc  对应出来染色体名字和所属类别\n",
    "category = []\n",
    "acc = {}\n",
    "for j in range(len(category)):\n",
    "    acc[category[j]] = {}\n",
    "    for i in range(name.shape[0]):\n",
    "        if name[i] = category[j]:\n",
    "            count = position_need[i].shape[0]    \n",
    "            acc[category[j]][name[i]] = (count - np.sum(rna_ic_correct_true - rna_ic_correct_pred))/count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
